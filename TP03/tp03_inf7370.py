# -*- coding: utf-8 -*-
"""TP03_INF7370.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-FPrDHaXfoHPjkPx-wreZKLfitY-sW5I
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf

# Check if GPU is available
if tf.config.list_physical_devices('GPU'):
  print("GPU is available. Setting TensorFlow to use GPU.")
  # Enable memory growth to avoid allocating all GPU memory at once
  gpus = tf.config.list_physical_devices('GPU')
  for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
else:
  print("GPU is not available. TensorFlow will use CPU instead.")

# First, unzip the donnees.zip file
import os
import zipfile

# Path to the zip file
zip_path = '/content/drive/MyDrive/donnees.zip'  # Adjust this path if needed based on your actual location

# Create a directory to extract to (if it doesn't exist)
extract_dir = '/content/donnees'
os.makedirs(extract_dir, exist_ok=True)

# Extract the zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print(f"Files extracted to {extract_dir}")

# Now set mainDataPath to the extracted directory
mainDataPath = "/content/donnees/"

# Check the structure of the extracted directory
print("\nContents of the extracted directory:")
for root, dirs, files in os.walk(mainDataPath):
    level = root.replace(mainDataPath, '').count(os.sep)
    indent = ' ' * 4 * level
    print(f"{indent}{os.path.basename(root)}/")
    sub_indent = ' ' * 4 * (level + 1)
    for file in files[:5]:  # Limit to first 5 files to prevent too much output
        print(f"{sub_indent}{file}")
    if len(files) > 5:
        print(f"{sub_indent}... ({len(files) - 5} more files)")

# **************************************************************************
# INF7370 Apprentissage automatique
# Travail pratique 2
# Nom: Abdoulaye Balde
# ===========================================================================

# #===========================================================================
# Ce modèle est un classifieur (un CNN) entrainé pour distinguer entre six espèces marines:
# 1. Baleine
# 2. Dauphin
# 3. Morse
# 4. Phoque
# 5. Requin
# 6. Requin-Baleine
#
# Données:
# ------------------------------------------------
# entrainement : 6 classes, 4 000 images chacune = 24 000 images
# test : 6 classes, 1 000 images chacune = 6 000 images
# ------------------------------------------------

# ==========================================
# ======CHARGEMENT DES LIBRAIRIES===========
# ==========================================

from tensorflow import keras
import time

# La libraire responsable du chargement des données dans la mémoire
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Le Type de notre modéle (séquentiel)
from keras.models import Model
from keras.models import Sequential

# Le type d'optimisateur utilisé dans notre modèle
from keras.optimizers import Adam

# Les types des couches utlilisées dans notre modèle
from keras.layers import (
    Conv2D,
    MaxPooling2D,
    Input,
    BatchNormalization,
    UpSampling2D,
    Activation,
    Dropout,
    Flatten,
    Dense,
)

# Des outils pour suivre et gérer l'entrainement de notre modèle
from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# Configuration du GPU
import tensorflow as tf
from keras import backend as K

# Assurer que TensorFlow utilise le GPU
physical_devices = tf.config.list_physical_devices('GPU')
if len(physical_devices) > 0:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
    print('GPU disponible et configuré!')
else:
    print('Aucun GPU détecté, utilisation du CPU')

# Sauvegarde du modèle
from keras.models import load_model

# Affichage des graphes
import matplotlib.pyplot as plt

# ==========================================
# ================VARIABLES=================
# ==========================================

# Le dossier principal qui contient les données
mainDataPath = "/content/donnees/donnees/"

# ==========================================
# ================VARIABLES=================
# ==========================================

# # The main directory containing the data
mainDataPath = "/content/donnees/donnees/"

# Directories containing training and test images
trainPath = mainDataPath + "entrainement"
testPath = mainDataPath + "test"

# Path to save the model
model_path = "Model.keras"

# Dataset sizes and split
total_training_images = 3600  # 1800 dolphins + 1800 sharks
validation_split = 0.1  # 10% for validation
training_ds_size = int(total_training_images * (1 - validation_split))  # 90% for training
validation_ds_size = int(total_training_images * validation_split)  # 10% for validation

# Image configuration
image_scale = 128       # Adjust based on your actual images
image_channels = 3      # 3 for RGB color images
images_color_mode = "rgb"  # For color images
image_shape = (image_scale, image_scale, image_channels)

# Training configuration
fit_batch_size = 32
fit_epochs = 100

# ==========================================
# ==========CHARGEMENT DES IMAGES===========
# ==========================================

# Use validation_split parameter in ImageDataGenerator for automatic splitting
training_data_generator = ImageDataGenerator(
    rescale=1./255,
    validation_split=validation_split  # This will split the data into training and validation
)

# Generator for training data (subset='training')
training_generator = training_data_generator.flow_from_directory(
    trainPath,
    color_mode=images_color_mode,
    target_size=(image_scale, image_scale),
    batch_size=fit_batch_size,
    class_mode="input",
    subset='training'  # Specify this is the training set
)

# Generator for validation data (subset='validation')
validation_generator = training_data_generator.flow_from_directory(
    trainPath,
    color_mode=images_color_mode,
    target_size=(image_scale, image_scale),
    batch_size=fit_batch_size,
    class_mode="input",
    subset='validation'  # Specify this is the validation set
)

# ==========================================
# ==============ENTRAINEMENT================
# ==========================================

# Model checkpoint to save the best model
modelcheckpoint = ModelCheckpoint(
    filepath=model_path,
    monitor='val_loss',
    verbose=1,
    save_best_only=True,
    mode='auto'
)

# Add timing code
import time
start_time = time.time()

# Training the model using generators
autoencoder = model.fit(
    training_generator,
    steps_per_epoch=training_generator.samples // fit_batch_size,
    epochs=fit_epochs,
    verbose=1,
    callbacks=[modelcheckpoint],
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // fit_batch_size
)

# Calculate and display execution time
execution_time = time.time() - start_time
print(f"Temps d'exécution total: {execution_time/60:.2f} minutes")

# ==========================================
# ========AFFICHAGE DES RESULTATS===========
# ==========================================

# Plot the loss curves
plt.figure(figsize=(10, 5))
plt.plot(autoencoder.history['loss'], label='Train Loss')
plt.plot(autoencoder.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.savefig('model_loss.png')
plt.show()

"""## Evaluation"""

# ==========================================
# ================VARIABLES=================
# ==========================================

# The main directory containing the data
mainDataPath = "donnees/"

# Path for test data
datapath = mainDataPath + "test"

# Total number of test images
number_images = 600  # 600 test images total
number_images_class_0 = 300  # 300 dolphin images
number_images_class_1 = 300  # 300 shark images

# Create labels for the test data
labels = np.array([0] * number_images_class_0 + [1] * number_images_class_1)

# Image configuration
image_scale = 128  # Should match the training configuration
images_color_mode = "rgb"  # Should match the training configuration

# ==========================================
# =========CHARGEMENT DES IMAGES============
# ==========================================

# Load test images
data_generator = ImageDataGenerator(rescale=1./255)

generator = data_generator.flow_from_directory(
    datapath,
    color_mode=images_color_mode,
    target_size=(image_scale, image_scale),
    batch_size=number_images,
    class_mode=None,
    shuffle=False
)

x = generator.__next__()  # Load all test images

# ==========================================
# ==========RECONSTRUCTION EVALUATION=======
# ==========================================

# Get reconstructions using the autoencoder
decoded_images = autoencoder.predict(x)

# Display original and reconstructed images for each class
plt.figure(figsize=(12, 6))

# Dolphin image (class 0)
dolphin_idx = 10  # Pick an index from the first class
plt.subplot(2, 2, 1)
plt.title('Dauphin (originale)')
plt.imshow(x[dolphin_idx])
plt.subplot(2, 2, 2)
plt.title('Dauphin (reconstruite)')
plt.imshow(decoded_images[dolphin_idx])

# Shark image (class 1)
shark_idx = number_images_class_0 + 10  # Pick an index from the second class
plt.subplot(2, 2, 3)
plt.title('Requin (originale)')
plt.imshow(x[shark_idx])
plt.subplot(2, 2, 4)
plt.title('Requin (reconstruite)')
plt.imshow(decoded_images[shark_idx])

plt.savefig('reconstructed_images.png')
plt.show()

# ==========================================
# =============EMBEDDING EXTRACTION=========
# ==========================================

# Define encoder model to extract embeddings
input_layer_index = 0
output_layer_index = 9  # Adjust based on your model architecture

# Create the encoder model from the autoencoder
encoder = Model(autoencoder.input, autoencoder.layers[output_layer_index].output)

# Extract embeddings for test images
embeddings = encoder.predict(x)

# Flatten the embeddings to prepare for classification
flattened_embeddings = embeddings.reshape(embeddings.shape[0], -1)
print(f"Embedding shape before flattening: {embeddings.shape}")
print(f"Embedding shape after flattening: {flattened_embeddings.shape}")

# Normalize the embeddings using StandardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
normalized_embeddings = scaler.fit_transform(flattened_embeddings)

# ==========================================
# ==============SVM CLASSIFICATION==========
# ==========================================

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Prepare original images for SVM (flatten)
original_flattened = x.reshape(x.shape[0], -1)

# Apply SVM on original images
print("Applying SVM on original images...")
svm_original = SVC(kernel='linear')
scores_original = cross_val_score(svm_original, original_flattened, labels, cv=5, scoring='accuracy')
print(f"SVM on original images - Accuracy: {scores_original.mean():.4f} ± {scores_original.std():.4f}")

# Apply SVM on normalized embeddings
print("Applying SVM on embeddings...")
svm_embeddings = SVC(kernel='linear')
scores_embeddings = cross_val_score(svm_embeddings, normalized_embeddings, labels, cv=5, scoring='accuracy')
print(f"SVM on embeddings - Accuracy: {scores_embeddings.mean():.4f} ± {scores_embeddings.std():.4f}")

# ==========================================
# ==============TSNE VISUALIZATION==========
# ==========================================

from sklearn.manifold import TSNE

# Apply TSNE for dimensionality reduction
print("Applying TSNE for visualization...")
tsne = TSNE(n_components=2, random_state=42)
embeddings_2d = tsne.fit_transform(normalized_embeddings)

# Visualize the embeddings
plt.figure(figsize=(10, 8))
colors = ['blue', 'black']
target_names = ['Dauphin', 'Requin']

for i, color in zip(range(len(target_names)), colors):
    plt.scatter(
        embeddings_2d[labels == i, 0],
        embeddings_2d[labels == i, 1],
        color=color,
        label=target_names[i]
    )

plt.legend()
plt.title('t-SNE Visualization of the Embeddings')
plt.savefig('tsne_embeddings.png')
plt.show()